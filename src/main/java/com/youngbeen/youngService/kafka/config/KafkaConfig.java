package com.youngbeen.youngService.kafka.config;


import com.youngbeen.youngService.DTO.BulkUpdateTaskDTO;
import com.youngbeen.youngService.DTO.MessageDTO;
import com.youngbeen.youngService.DTO.StockInfoDTO;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.kafka.support.serializer.ErrorHandlingDeserializer;
import org.springframework.kafka.support.serializer.JsonDeserializer;
import org.springframework.kafka.support.serializer.JsonSerializer;
import org.springframework.util.backoff.FixedBackOff;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class KafkaConfig {
    // Producer ì„¤ì • + Consumer ì„¤ì • + ì˜¤ë¥˜ ì²˜ë¦¬


    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    // ========== ê³µí†µ Producer ì„¤ì • ==========
    private Map<String, Object> getProducerProps() {
        Map<String, Object> configProps = new HashMap<>();
        // Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        // í‚¤ ì§ë ¬í™”: String â†’ ë°”ì´íŠ¸
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        // ê°’ ì§ë ¬í™”: Java ê°ì²´ â†’ JSON â†’ ë°”ì´íŠ¸
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        // ëª¨ë“  íŒŒí‹°ì…˜ì—ì„œ í™•ì¸ í›„ ì‘ë‹µ (ì•ˆì „ì„± ìµœëŒ€)
        configProps.put(ProducerConfig.ACKS_CONFIG, "all");
        // ì‹¤íŒ¨ ì‹œ 3ë²ˆ ì¬ì‹œë„
        configProps.put(ProducerConfig.RETRIES_CONFIG, 3);
        return configProps;
    }

    // ========== MessageDTO ì„¤ì • ==========
    @Bean
    public ProducerFactory<String, MessageDTO> messageProducerFactory() {
        return new DefaultKafkaProducerFactory<>(getProducerProps());
    }

    //íƒ€ì…ë³„ Producer Bean
    // MessageDTO ì „ìš© Producer
    @Bean("messageKafkaTemplate")  // ğŸ”§ ëª…ì‹œì  Bean ì´ë¦„ ì§€ì •
    public KafkaTemplate<String, MessageDTO> messageKafkaTemplate() {
        return new KafkaTemplate<>(messageProducerFactory());
    }

    // BulkUpdateTaskDTO ì „ìš© Producer
    @Bean("bulkUpdateKafkaTemplate")  // ğŸ”§ ëª…ì‹œì  Bean ì´ë¦„ ì§€ì •
    public KafkaTemplate<String, BulkUpdateTaskDTO> bulkUpdateKafkaTemplate() {
        return new KafkaTemplate<>(bulkUpdateProducerFactory());
    }

    @Bean
    public ConsumerFactory<String, MessageDTO> messageConsumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "test-group-fixed-v1");  // ğŸ”§ ìƒˆë¡œìš´ ê·¸ë£¹ ID
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");  // ğŸ”§ ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì‹œì‘

        // ğŸ”§ ErrorHandlingDeserializer ì‚¬ìš©
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);

        // ì‹¤ì œ Deserializer ì„¤ì •
        props.put(ErrorHandlingDeserializer.KEY_DESERIALIZER_CLASS, StringDeserializer.class);
        props.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);

        // JsonDeserializer ì„¤ì •
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        props.put(JsonDeserializer.USE_TYPE_INFO_HEADERS, false);
        props.put(JsonDeserializer.VALUE_DEFAULT_TYPE, MessageDTO.class.getName());

        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, MessageDTO> messageKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, MessageDTO> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(messageConsumerFactory());

        // ğŸ”§ ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(
                (consumerRecord, exception) -> {
                    System.err.println("=== MessageDTO ì²˜ë¦¬ ì‹¤íŒ¨ - ê±´ë„ˆë›°ê¸° ===");
                    System.err.println("í† í”½: " + consumerRecord.topic());
                    System.err.println("ì˜¤í”„ì…‹: " + consumerRecord.offset());
                    System.err.println("í‚¤: " + consumerRecord.key());
                    System.err.println("ì˜¤ë¥˜: " + exception.getMessage());
                    System.err.println("=====================================");
                },
                new FixedBackOff(0L, 0L) // ì¬ì‹œë„ ì•ˆí•¨, ë°”ë¡œ ê±´ë„ˆë›°ê¸°
        );

        // ëª¨ë“  ì—­ì§ë ¬í™” ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
        errorHandler.addNotRetryableExceptions(
                org.springframework.kafka.support.serializer.DeserializationException.class,
                org.apache.kafka.common.errors.RecordDeserializationException.class,
                IllegalStateException.class,
                com.fasterxml.jackson.core.JsonProcessingException.class
        );

        factory.setCommonErrorHandler(errorHandler);
        return factory;
    }

    // ========== BulkUpdateTaskDTO ì„¤ì • ==========
    @Bean
    public ProducerFactory<String, BulkUpdateTaskDTO> bulkUpdateProducerFactory() {
        return new DefaultKafkaProducerFactory<>(getProducerProps());
    }

    @Bean
    public ConsumerFactory<String, BulkUpdateTaskDTO> bulkUpdateConsumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        // ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì´ë¦„ (ê°™ì€ ê·¸ë£¹ì€ ë©”ì‹œì§€ë¥¼ ë‚˜ëˆ ì„œ ì²˜ë¦¬)
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "bulk-update-group-fixed-v1");  // ğŸ”§ ìƒˆë¡œìš´ ê·¸ë£¹ ID
        // ì²˜ìŒ ì‹œì‘í•  ë•Œ ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì½ê¸°
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");  // ğŸ”§ ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì‹œì‘

        //  ErrorHandlingDeserializer ì‚¬ìš©
        // ErrorHandlingDeserializer: ì—­ì§ë ¬í™” ì˜¤ë¥˜ ì²˜ë¦¬
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer.class);

        // ì‹¤ì œ Deserializer ì„¤ì •
        props.put(ErrorHandlingDeserializer.KEY_DESERIALIZER_CLASS, StringDeserializer.class);
        props.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);

        // JsonDeserializer ì„¤ì •
        // ëª¨ë“  íŒ¨í‚¤ì§€ì˜ í´ë˜ìŠ¤ ì—­ì§ë ¬í™” í—ˆìš©
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        // í—¤ë”ì˜ íƒ€ì… ì •ë³´ ë¬´ì‹œ
        props.put(JsonDeserializer.USE_TYPE_INFO_HEADERS, false);

        // ê¸°ë³¸ì ìœ¼ë¡œ BulkUpdateTaskDTOë¡œ ì—­ì§ë ¬í™”
        props.put(JsonDeserializer.VALUE_DEFAULT_TYPE, BulkUpdateTaskDTO.class.getName());

        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, BulkUpdateTaskDTO> bulkUpdateKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, BulkUpdateTaskDTO> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(bulkUpdateConsumerFactory());

        // ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(
                (consumerRecord, exception) -> {
                    // ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡œê¹… í›„ ê±´ë„ˆë›°ê¸°
                    System.err.println("=== BulkUpdateTaskDTO ì²˜ë¦¬ ì‹¤íŒ¨ - ê±´ë„ˆë›°ê¸° ===");
                    System.err.println("í† í”½: " + consumerRecord.topic());
                    System.err.println("íŒŒí‹°ì…˜: " + consumerRecord.partition());
                    System.err.println("ì˜¤í”„ì…‹: " + consumerRecord.offset());
                    System.err.println("í‚¤: " + consumerRecord.key());
                    System.err.println("ì˜¤ë¥˜: " + exception.getMessage());
                    System.err.println("===========================================");
                },
                new FixedBackOff(0L, 0L) // ì¬ì‹œë„ ì•ˆí•¨, ë°”ë¡œ ê±´ë„ˆë›°ê¸°
        );

        // ëª¨ë“  ì—­ì§ë ¬í™” ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
        errorHandler.addNotRetryableExceptions(
                org.springframework.kafka.support.serializer.DeserializationException.class,
                org.apache.kafka.common.errors.RecordDeserializationException.class,
                IllegalStateException.class,
                com.fasterxml.jackson.core.JsonProcessingException.class,
                com.fasterxml.jackson.databind.JsonMappingException.class
        );

        factory.setCommonErrorHandler(errorHandler);
        return factory;
    }

}
