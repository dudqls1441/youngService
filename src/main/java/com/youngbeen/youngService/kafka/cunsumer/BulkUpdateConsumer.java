package com.youngbeen.youngService.kafka.cunsumer;

import com.youngbeen.youngService.DTO.BulkUpdateTaskDTO;
import com.youngbeen.youngService.Mapper.StockInfoMapper;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;
import java.util.List;

// Consumer - "ì–´ë–»ê²Œ í• ì§€" ì‹¤ì œ êµ¬í˜„
@Component
@Slf4j
class BulkUpdateConsumer {
    @Autowired
    private StockInfoMapper stockInfoMapper;

    @KafkaListener(topics = "bulk-update-topic",
            groupId = "bulk-update-group-fixed-v1",
            containerFactory = "bulkUpdateKafkaListenerContainerFactory")
    public void processBulkUpdate(BulkUpdateTaskDTO task) {
        String taskId = task.getTaskId();
        String taskType = task.getTaskType();

        log.info("ì‘ì—… ìˆ˜ì‹ : {} - {}", taskId, taskType);
        log.info("Processing bulk update task: {}", task);

        try {
            // ğŸ”§ ìƒìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ì… ë¹„êµ
            if (BulkUpdateTaskDTO.TASK_TYPE_UPDATE_REMARKS.equals(taskType)) {
                // ê¸°ì¡´ ë¡œì§: REMARKS ì—…ë°ì´íŠ¸
                processRemarksUpdate(task);

            } else if (BulkUpdateTaskDTO.TASK_TYPE_RESET_REMARKS.equals(taskType)) {
                // ìƒˆë¡œìš´ ë¡œì§: REMARKS ì´ˆê¸°í™”
                processRemarksReset(task);

            } else {
                log.warn("ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… íƒ€ì…: {}", taskType);
                throw new IllegalArgumentException("Unknown task type: " + taskType);
            }

        } catch (Exception e) {
            log.error("Bulk update task failed: {}", taskId, e);
        }
    }

    // ë¹„ê³  ì—…ë°ì´íŠ¸ ì²˜ë¦¬ (ë°©ë²• 1: í•œ ë²ˆì— ì²˜ë¦¬)
    private void processRemarksUpdate(BulkUpdateTaskDTO task) {
        String taskId = task.getTaskId();

        log.info("Starting remarks update - Total records: {}", task.getTotalCount());
        log.info("ëŒ€ëŸ‰ ì—…ë°ì´íŠ¸ ì‹œì‘: ë¹„ê³  ì»¬ëŸ¼ì— BASDT ê°’ì„ ì…ë ¥í•©ë‹ˆë‹¤.");

        try {
            // ë°©ë²• 1: í•œ ë²ˆì— ëª¨ë“  ë°ì´í„° ì—…ë°ì´íŠ¸ (ê°€ì¥ ë¹ ë¦„)
            long startTime = System.currentTimeMillis();
            int updatedRows = stockInfoMapper.updateAllRemarksWithBasDt();
            long endTime = System.currentTimeMillis();

            log.info("Bulk update completed: {} rows updated in {} ms",
                    updatedRows, (endTime - startTime));

        } catch (Exception e) {
            log.error("Failed to update remarks in bulk", e);

            // ì‹¤íŒ¨ ì‹œ ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
            processBatchUpdate(task);
        }
    }

    // ë°°ì¹˜ ë°©ì‹ ì—…ë°ì´íŠ¸ (ë°©ë²• 2: ì•ˆì „í•œ ë°©ì‹)
    private void processBatchUpdate(BulkUpdateTaskDTO task) {
        String taskId = task.getTaskId();
        int batchSize = task.getBatchSize();

        log.info("Starting batch update with batch size: {}", batchSize);
        log.info("âš ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.");

        long totalProcessed = 0;
        long totalSuccess = 0;
        long totalFailed = 0;

        // BASDTë³„ë¡œ ì²˜ë¦¬
        long offset = 0;
        List<String> basDtBatch;

        do {
            // BASDT ëª©ë¡ì„ ë°°ì¹˜ë¡œ ì¡°íšŒ
            basDtBatch = stockInfoMapper.getBasDtBatch(offset, batchSize);

            for (String basDt : basDtBatch) {
                try {
                    // í•´ë‹¹ BASDTì˜ ëª¨ë“  ë ˆì½”ë“œë¥¼ ë¹„ê³ ì— BASDT ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    int updated = stockInfoMapper.updateRemarksByBasDt(basDt, basDt);

                    totalProcessed += updated;
                    totalSuccess += updated;

                    log.debug("Updated {} records for BASDT: {}", updated, basDt);

                } catch (Exception e) {
                    long failedCount = stockInfoMapper.getCountByBasDt(basDt);
                    totalProcessed += failedCount;
                    totalFailed += failedCount;

                    log.error("Failed to update BASDT: {}", basDt, e);
                }
            }

            // ì¤‘ê°„ ë¡œê·¸ (1ë§Œê±´ë§ˆë‹¤)
            if (totalProcessed % 10000 == 0 && totalProcessed > 0) {
                log.info("ì§„í–‰ìƒí™©: {}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì™„ë£Œ", totalProcessed);
            }

            offset += batchSize;

            // ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            }

        } while (!basDtBatch.isEmpty());

        log.info("âœ… Batch update completed: {} processed, {} success, {} failed",
                totalProcessed, totalSuccess, totalFailed);
    }

    // ì´ˆê¸°í™”
    private void processRemarksReset(BulkUpdateTaskDTO task) {
        String taskId = task.getTaskId();

        log.info("Starting remarks reset - Total records: {}", task.getTotalCount());
        log.info("ëŒ€ëŸ‰ ì´ˆê¸°í™” ì‹œì‘: ë¹„ê³  ì»¬ëŸ¼ì„ NULLë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.");

        try {
            // ë°©ë²• 1: í•œ ë²ˆì— ëª¨ë“  ë°ì´í„° ì´ˆê¸°í™”
            long startTime = System.currentTimeMillis();
            int resetRows = stockInfoMapper.resetAllRemarksToNull();
            long endTime = System.currentTimeMillis();

            log.info("Bulk reset completed: {} rows reset to NULL in {} ms",
                    resetRows, (endTime - startTime));

        } catch (Exception e) {
            log.error("Failed to reset remarks in bulk", e);

            // ì‹¤íŒ¨ ì‹œ ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
            processBatchReset(task);
        }
    }

    // ë°°ì¹˜ ë°©ì‹ ì´ˆê¸°í™”
    private void processBatchReset(BulkUpdateTaskDTO task) {
        String taskId = task.getTaskId();
        int batchSize = task.getBatchSize();

        log.info("Starting batch reset with batch size: {}", batchSize);
        log.info("ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.");

        long totalProcessed = 0;
        long totalSuccess = 0;
        long totalFailed = 0;

        // ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        long offset = 0;

        do {
            try {
                // ë°°ì¹˜ ë‹¨ìœ„ë¡œ REMARKSë¥¼ NULLë¡œ ì—…ë°ì´íŠ¸
                int resetCount = stockInfoMapper.resetRemarksBatch(offset, batchSize);

                if (resetCount > 0) {
                    totalProcessed += resetCount;
                    totalSuccess += resetCount;

                    log.debug("Reset {} records at offset: {}", resetCount, offset);

                    // ì¤‘ê°„ ë¡œê·¸ (1ë§Œê±´ë§ˆë‹¤)
                    if (totalProcessed % 10000 == 0) {
                        log.info("ğŸ§¹ ì´ˆê¸°í™” ì§„í–‰ìƒí™©: {}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì™„ë£Œ", totalProcessed);
                    }

                    offset += batchSize;

                    // ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
                    Thread.sleep(50);
                } else {
                    // ë” ì´ìƒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŒ
                    break;
                }

            } catch (Exception e) {
                totalFailed += batchSize;
                log.error("Failed to reset batch at offset: {}", offset, e);

                offset += batchSize; // ë‹¤ìŒ ë°°ì¹˜ë¡œ ê³„ì† ì§„í–‰
            }

        } while (true);

        log.info("Batch reset completed: {} processed, {} success, {} failed",
                totalProcessed, totalSuccess, totalFailed);
    }
}
